lazy memory migration é€™å€‹æ¦‚å¿µåœ¨ CUDAã€NUMAï¼ˆNon-Uniform Memory Accessï¼‰ã€ç”šè‡³ä½œæ¥­ç³»çµ±è™›æ“¬è¨˜æ†¶é«”ç®¡ç†ä¸­éƒ½å¾ˆé‡è¦ã€‚è®“æˆ‘å¹«ä½ å¾å·¥ç¨‹å¸«è¦–è§’æŠŠå®ƒæ‹†é–‹è¬›ğŸ‘‡

ğŸ§  å®šç¾©ï¼šLazy Memory Migration æ˜¯ä»€éº¼ï¼Ÿ

Lazy Memory Migration = å»¶é²çš„è¨˜æ†¶é«”é é¢æ¬ç§»ã€‚
ç³»çµ±ä¸æœƒç«‹å³æŠŠè³‡æ–™å¾ä¸€å€‹å¯¦é«”è¨˜æ†¶é«”ï¼ˆä¾‹å¦‚ GPU0 â†’ GPU1 æˆ– CPU â†’ GPUï¼‰ç§»å‹•éå»ï¼Œè€Œæ˜¯ç­‰ã€Œç¬¬ä¸€æ¬¡è¢«å¯¦éš›å­˜å–ã€æ™‚æ‰æ¬ã€‚

ç°¡å–®æ¯”å–»ï¼š

å°±åƒè¡Œææ‰˜é‹ä¸æ˜¯ä½ ç™»æ©Ÿæ™‚é¦¬ä¸Šé€åˆ°ä½ ç›®çš„åœ°ï¼Œè€Œæ˜¯ä½ ã€Œåˆ°é‚£å€‹åŸå¸‚ä¸¦æ‰“é–‹è¡Œæã€æ™‚ï¼Œæ©Ÿå ´æ‰æ´¾äººæŠŠå®ƒæ¬ä¾†ã€‚

ğŸ§© åœ¨ CUDA Unified Memory è£¡çš„ Lazy Migration

ç•¶ä½ ç”¨ï¼š

``` cpp
cudaMallocManaged(&ptr, size);
```

é€™å¡Šè¨˜æ†¶é«”æ˜¯ã€Œçµ±ä¸€ä½å€ç©ºé–“ã€çš„ä¸€éƒ¨åˆ†ï¼ŒCPU èˆ‡ GPU éƒ½èƒ½çœ‹åˆ°å®ƒã€‚
ä½†æ˜¯ï¼ è³‡æ–™ä¸æœƒé¦¬ä¸Šè¤‡è£½åˆ° GPUã€‚

é‹ä½œæ©Ÿåˆ¶ï¼š
1. ä½ åœ¨ CPU ä¸Šåˆå§‹åŒ– ptr â†’ è³‡æ–™æ”¾åœ¨ host memoryã€‚
2. ä½ å‘¼å« kernel ç”¨ GPU å­˜å– ptrã€‚
3. GPU ç¬¬ä¸€æ¬¡ access è©²é ï¼ˆ4KBï¼‰æ™‚ç™¼ç”Ÿ page faultã€‚
4. CUDA driver æŠŠè©²é ã€Œlazyã€åœ°å¾ host memory æ¬åˆ° GPU çš„ device memoryã€‚
5. åŒé ä¹‹å¾Œçš„ GPU å­˜å–å°±ä¸å†éœ€è¦ faultã€‚

âš™ï¸ é€™æ•´å€‹éç¨‹å« on-demand page migrationï¼ˆæŒ‰éœ€æ¬ç§»ï¼‰ï¼Œ
è€Œã€Œlazyã€å°±æ˜¯æŒ‡å®ƒä¸é å…ˆåšé€™ä»¶äº‹ï¼Œç­‰ä½ çœŸçš„ç”¨åˆ°æ‰æ¬ã€‚

ğŸš€ å¯¦éš›æ•ˆèƒ½å½±éŸ¿

| ç‹€æ³        | çµæœ                                |
| --------- | --------------------------------- |
| å°è¦æ¨¡æˆ–ä¸é€£çºŒå­˜å– | Lazy migration å¾ˆæ–¹ä¾¿ï¼Œä¸æµªè²»æ™‚é–“æ¬æ•´å¡Šè¨˜æ†¶é«”ã€‚   |
| å¤§è¦æ¨¡å¯†é›†å­˜å–   | ç¬¬ä¸€æ¬¡å­˜å–æ™‚æœƒæœ‰å¤§é‡ page fault â†’ å»¶é²çˆ†ç‚¸ã€‚     |
| è§£æ³•        | æ­é… `cudaMemPrefetchAsync()` é å…ˆæ¬ç§»ã€‚ |

ä¾‹å¦‚ï¼š

``` cpp
int *data;
cudaMallocManaged(&data, N * sizeof(int));

// é å…ˆæŠŠè³‡æ–™æ¬å» GPU
cudaMemPrefetchAsync(data, N * sizeof(int), device_id, stream);
```

ğŸ§© åœ¨ NUMA / OS å±¤çš„ Lazy Migration

é€™æ¦‚å¿µä¹Ÿå‡ºç¾åœ¨ Linux çš„ NUMA page migrationï¼š
ç•¶ thread è·‘åœ¨ Node 1ï¼Œä½†è³‡æ–™åŸæœ¬åœ¨ Node 0 çš„è¨˜æ†¶é«”æ™‚ï¼Œkernel å¯èƒ½æœƒåœ¨ä½ ç¬¬ä¸€æ¬¡ access æ™‚æ‰æ¬ç§»é é¢ï¼ˆlazy migrateï¼‰ã€‚
é€™è®“ç³»çµ±èƒ½å¹³è¡¡è¨˜æ†¶é«”ç†±åº¦ï¼ˆmemory localityï¼‰è€Œä¸æµªè²» IO å¸¶å¯¬ã€‚

ğŸ§  å»¶ä¼¸ï¼šGPU Direct + Lazy Migration çš„è¡çª

å¦‚æœä½ ä½¿ç”¨ï¼š

Pinned memory

Zero-copy (cudaHostRegister)

GPUDirect RDMA

é‚£é€™äº›æ©Ÿåˆ¶æœƒã€Œç¹éã€lazy migration æ©Ÿåˆ¶ã€‚
å› ç‚ºé€™äº›è¨˜æ†¶é«”å·²ç¶“æ˜ç¢ºç¶å®šåˆ°ç‰¹å®š bus æˆ–è£ç½®ï¼Œdriver ä¸å…è¨± page fault æ¬ä¾†æ¬å»ã€‚

âš¡ ç¸½çµä¸€å¥è©±ï¼š

Lazy memory migration = "Don't move memory until you really touch it."
åœ¨ CUDA Unified Memory æˆ– NUMA ç³»çµ±ä¸­ï¼Œå®ƒè®“è¨˜æ†¶é«”åˆ†é…æ›´éˆæ´»ï¼Œä½†è‹¥æ²’é å…ˆé·ç§»ï¼Œé¦–æ¬¡å­˜å–ä»£åƒ¹æ¥µé«˜ã€‚

### cudaMemPrefetchAsync()
cudaMemPrefetchAsync() æ˜¯ Unified Memoryï¼ˆçµ±ä¸€è¨˜æ†¶é«”ï¼‰ä¸­ã€Œå lazy memory migrationã€çš„æ­¦å™¨ã€‚
å®ƒè®“ä½ ä¸»å‹•æŠŠè³‡æ–™æ¬åˆ°æŒ‡å®šçš„è£ç½®ï¼ˆCPU æˆ– GPUï¼‰ï¼Œè€Œä¸æ˜¯ç­‰åˆ° kernel åŸ·è¡Œæ™‚æ‰ page fault ä¸€é ä¸€é æ¬ã€‚

ğŸš€ ä¸€å¥è©±è§£é‡‹

cudaMemPrefetchAsync()ï¼š
æŠŠ Unified Memory çš„è³‡æ–™ã€Œé å…ˆã€æ¬ç§»ï¼ˆprefetchï¼‰åˆ°æŒ‡å®šçš„è£ç½®ä¸Šï¼ŒéåŒæ­¥åŸ·è¡Œï¼Œé¿å… Lazy Migration çš„å»¶é²ã€‚

ğŸ“˜ å‡½å¼å®šç¾©

``` cpp
cudaError_t cudaMemPrefetchAsync(
    const void* devPtr, 
    size_t count, 
    int dstDevice, 
    cudaStream_t stream = 0
);
```

ğŸ”¹åƒæ•¸èªªæ˜ï¼š

| åƒæ•¸          | æ„ç¾©                                                            |
| ----------- | ------------------------------------------------------------- |
| `devPtr`    | æŒ‡å‘ç”¨ `cudaMallocManaged()` é…ç½®çš„ Unified Memory æŒ‡æ¨™               |
| `count`     | è¦æ¬ç§»çš„è¨˜æ†¶é«”å¤§å°ï¼ˆbytesï¼‰                                              |
| `dstDevice` | ç›®æ¨™è£ç½®ä»£è™Ÿï¼š<br>â†’ `cudaCpuDeviceId`ï¼šæ¬å› host<br>â†’ GPU IDï¼ˆ0, 1, ...ï¼‰ |
| `stream`    | éåŒæ­¥ streamï¼ˆå¯ç‚º 0 = default streamï¼‰                             |

ğŸ§  é‹ä½œåŸç†
é è¨­æƒ…æ³ï¼ˆlazy migrationï¼‰ï¼š

``` bash
CPU åˆå§‹åŒ–è³‡æ–™
â†“
GPU kernel åŸ·è¡Œ â†’ page fault
â†“
CUDA Driver æ‰æ¬è³‡æ–™ â†’ å»¶é²å¢åŠ 
```
ä½¿ç”¨ cudaMemPrefetchAsync() å¾Œï¼š

``` cpp
CPU åˆå§‹åŒ–è³‡æ–™
â†“
cudaMemPrefetchAsync(data, size, gpu)
â†“
è³‡æ–™é å…ˆæ¬åˆ° GPU
â†“
GPU kernel åŸ·è¡Œ â†’ ç„¡ page fault
```

ğŸ§© ç¯„ä¾‹

``` cpp
#include <cuda_runtime.h>
#include <iostream>

__global__ void kernel(int *data) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    data[idx] *= 2;
}

int main() {
    const int N = 1 << 20;
    int *data;

    // åˆ†é… Unified Memory
    cudaMallocManaged(&data, N * sizeof(int));

    // åˆå§‹åŒ–åœ¨ CPU ç«¯
    for (int i = 0; i < N; i++) data[i] = i;

    int device;
    cudaGetDevice(&device);

    // é å–åˆ° GPU
    cudaMemPrefetchAsync(data, N * sizeof(int), device);

    // ç­‰å¾…æ¬ç§»å®Œæˆ
    cudaDeviceSynchronize();

    kernel<<<N/256, 256>>>(data);
    cudaDeviceSynchronize();

    // é å–å› CPU
    cudaMemPrefetchAsync(data, N * sizeof(int), cudaCpuDeviceId);
    cudaDeviceSynchronize();

    std::cout << "data[42] = " << data[42] << std::endl;
    cudaFree(data);
}
```

âš™ï¸ å¯¦å‹™æ‡‰ç”¨å ´æ™¯

| å ´æ™¯                                 | æ˜¯å¦æ¨è–¦ä½¿ç”¨ `cudaMemPrefetchAsync()` |
| ---------------------------------- | ------------------------------- |
| **å¤§å‹çŸ©é™£æˆ–å½±åƒæ‰¹æ¬¡æ¨è«–å‰**                   | âœ… å¼·çƒˆå»ºè­°ï¼ˆé¿å… page fault stormï¼‰     |
| **å¤š GPU ç³»çµ±ï¼ˆUnified Memory è·¨ GPUï¼‰** | âœ… æ˜ç¢ºæŒ‡å®šç›®æ¨™ GPU                    |
| **CPU â†” GPU äº¤æ›¿æ“ä½œé »ç¹**               | âœ… é å…ˆå›é·åˆ° CPU                     |
| **Streaming pipeline**             | âœ… å¯æ­é…å¤š stream åˆ†æ®µæ¬ç§»              |
| **å°å‹ã€éš¨æ©Ÿå­˜å–è³‡æ–™**                      | âŒ Lazy migration æ›´æœ‰æ•ˆç‡           |

ğŸ”¥ é€²éšï¼šèˆ‡ cudaMemAdvise() çµåˆ
å¦‚æœä½ çŸ¥é“è³‡æ–™ä½¿ç”¨æ¨¡å¼ï¼Œå¯ä»¥å‘Šè¨´ CUDA driverï¼š

``` cpp
cudaMemAdvise(ptr, size, cudaMemAdviseSetPreferredLocation, device);
cudaMemAdvise(ptr, size, cudaMemAdviseSetAccessedBy, device);
```

- SetPreferredLocationï¼šå‘Šè¨´ driver é æœŸè³‡æ–™é•·é§åœ¨å“ªå€‹ GPU
- SetAccessedByï¼šè®“å…¶ä»– GPU ä¹Ÿèƒ½ç›´æ¥ access è€Œä¸æ¬ç§»

é€™å…©å€‹è¨­å®š + cudaMemPrefetchAsync()
â†’ ç­‰æ–¼æ˜¯ã€Œé¡¯å¼æ§åˆ¶ Unified Memory çš„ page policyã€ã€‚

âš¡ å°é™·é˜±

| å•é¡Œ                                          | åŸå›                                   |
| ------------------------------------------- | ----------------------------------- |
| âŒ åœ¨ malloc() åˆ†é…çš„è¨˜æ†¶é«”ä¸Šä½¿ç”¨æœƒå ±éŒ¯                   | åªèƒ½ç”¨åœ¨ `cudaMallocManaged()` é…ç½®çš„è¨˜æ†¶é«”   |
| âŒ å¿˜è¨˜ `cudaDeviceSynchronize()` å°±é¦¬ä¸Šå•Ÿå‹• kernel | Prefetch é‚„æ²’å®Œæˆï¼Œkernel å¯èƒ½æœƒ page fault |
| âŒ å¤š GPU æ²’æŒ‡å®šæ­£ç¢ºçš„ device ID                    | è³‡æ–™å¯èƒ½é‚„åœ¨éŒ¯çš„ GPU ä¸Šï¼Œå°è‡´ peer access fault |

ğŸ¯ çµè«–ä¸€å¥è©±

cudaMemPrefetchAsync() = ã€Œé å– + éåŒæ­¥ + æ§åˆ¶ Unified Memory page æ¬ç§»æ–¹å‘ã€ã€‚
åœ¨å¤§å‹ batch æ¨è«–æˆ– multi-GPU ç³»çµ±ä¸­ï¼Œæ˜¯æå‡æ•ˆèƒ½ã€é¿å… page fault çš„é—œéµ APIã€‚

Q: è¦å¦‚ä½•åˆ¤æ–·è³‡æ–™æ¬ç§»åˆ°é‚£å€‹è£ç½®ä¸Š

é€™æ­£æ˜¯å¾ˆå¤šåœ¨ç”¨ Unified Memory (cudaMallocManaged) çš„å·¥ç¨‹å¸«è¸©éçš„å¤§å‘ï¼šä½ çœ‹ä¸åˆ°è³‡æ–™åˆ°åº•åœ¨ CPU é‚„æ˜¯ GPU ä¸Šã€‚

ä½†å…¶å¯¦ CUDA æœ‰ä¸€æ•´å¥—æ©Ÿåˆ¶è®“ä½ ã€ŒæŸ¥ã€æ§ã€é æ¸¬ã€ Unified Memory çš„ page æ‰€åœ¨ä½ç½®ã€‚
ä¸‹é¢æˆ‘å¹«ä½ æ‹†æˆå¹¾å±¤èªªæ˜ ğŸ‘‡

ğŸ§© ä¸€ã€åŸºæœ¬æ¦‚å¿µï¼šUnified Memory çš„ã€Œé§ç•™ä½ç½® (residency)ã€

ç•¶ä½ ç”¨ cudaMallocManaged() åˆ†é…è¨˜æ†¶é«”å¾Œï¼š

é€™å¡Šè¨˜æ†¶é«”æœ‰ä¸€å€‹è™›æ“¬ä½å€ç©ºé–“ï¼›

å¯¦éš›çš„å¯¦é«”é é¢ï¼ˆ4KB ç‚ºå–®ä½ï¼‰æœƒã€Œlazy migrateã€åˆ°èª°ä½¿ç”¨å®ƒçš„é‚£å€‹è£ç½®ä¸Šï¼›

ä½ å¯ä»¥æŸ¥è©¢ç›®å‰å®ƒçš„ã€Œpreferred locationã€èˆ‡ã€Œå¯¦éš›é§ç•™ä½ç½®ã€ã€‚

ğŸ§° äºŒã€æŸ¥è©¢ç›®å‰è³‡æ–™åœ¨å“ªè£¡
âœ… æ–¹æ³• 1ï¼šcudaMemRangeGetAttribute()

é€™æ˜¯å®˜æ–¹æ¨è–¦çš„åšæ³•ã€‚

``` cpp
cudaError_t cudaMemRangeGetAttribute(
    void *data,
    size_t dataSize,
    cudaMemRangeAttribute attribute,
    const void *devPtr,
    size_t count
);
```

ä½ å¯ä»¥æŸ¥ï¼š
- cudaMemRangeAttributeLastPrefetchLocation
- cudaMemRangeAttributePreferredLocation
- cudaMemRangeAttributeAccessedBy

ğŸ”¹ ç¯„ä¾‹ï¼šæŸ¥è©¢å¯¦éš›æ¬ç§»åˆ°å“ªå€‹è£ç½®

``` cpp
#include <cuda_runtime.h>
#include <iostream>

int main() {
    int *ptr;
    const size_t N = 1 << 20;
    cudaMallocManaged(&ptr, N * sizeof(int));

    // åˆå§‹åŒ– (åœ¨ CPU)
    for (size_t i = 0; i < N; i++) ptr[i] = i;

    int device;
    cudaGetDevice(&device);

    // é å–åˆ° GPU
    cudaMemPrefetchAsync(ptr, N * sizeof(int), device);
    cudaDeviceSynchronize();

    int last_prefetch_loc = -1;
    cudaMemRangeGetAttribute(
        &last_prefetch_loc,
        sizeof(last_prefetch_loc),
        cudaMemRangeAttributeLastPrefetchLocation,
        ptr,
        N * sizeof(int)
    );

    if (last_prefetch_loc == cudaCpuDeviceId)
        std::cout << "è³‡æ–™ç›®å‰åœ¨ CPU" << std::endl;
    else
        std::cout << "è³‡æ–™ç›®å‰åœ¨ GPU " << last_prefetch_loc << std::endl;

    cudaFree(ptr);
}
```

ğŸ§  ä¸‰ã€é€²éšï¼šdriver å±¤èˆ‡ profiler è§€å¯Ÿ
âœ… 1. Nsight Systems / Nsight Compute

åœ¨ timeline è£¡æœƒçœ‹åˆ°ï¼š

``` bash
Unified Memory Memcpy HtoD
Unified Memory Memcpy DtoH
Unified Memory Page Fault
```

é€™äº› event æœƒé¡¯ç¤ºå‡ºè³‡æ–™è¢«æ¬ç§»åˆ°å“ªå€‹ GPUã€‚
ç”šè‡³é‚„æœƒé¡¯ç¤ºæ¬äº†å¹¾ MBï¼ˆæ¯å€‹ page fault éƒ½æ˜¯ 4KB å–®ä½ï¼‰ã€‚

âœ… 2. CUDA driver logï¼ˆdebugï¼‰

ä½ å¯ä»¥è¨­å®šç’°å¢ƒè®Šæ•¸ï¼š

``` bash
export CUDA_LAUNCH_BLOCKING=1
export CUDA_MEMCHECK=1
```

æˆ–æ›´é€²éšçš„ï¼š

``` bash
export CUDA_MANAGED_FORCE_DEVICE_ALLOC=1
export CUDA_VISIBLE_DEVICES=0
```

å†è§€å¯Ÿ logï¼Œå¯ä»¥çœ‹åˆ°å¯¦éš›çš„ fault èˆ‡æ¬ç§»ã€‚

âš™ï¸ å››ã€ç†è«–ç†è§£ï¼šè³‡æ–™ã€Œé§ç•™ã€ä¸ç­‰æ–¼ã€Œé–å®šã€

Unified Memory æœƒå‹•æ…‹èª¿æ•´é§ç•™ä½ç½®ã€‚
å³ä½¿ä½ å‰›æŸ¥åˆ°è³‡æ–™åœ¨ GPUï¼Œä¸‹ä¸€å€‹ CPU æ“ä½œä¹Ÿå¯èƒ½è§¸ç™¼æ¬å›ã€‚
é€™å°±æ˜¯ç‚ºä»€éº¼ cudaMemPrefetchAsync() é€šå¸¸è¦å’Œ cudaMemAdviseSetPreferredLocation ä¸€èµ·ä½¿ç”¨ã€‚

ç¯„ä¾‹ï¼š

``` cpp
cudaMemAdvise(ptr, size, cudaMemAdviseSetPreferredLocation, device);
cudaMemAdvise(ptr, size, cudaMemAdviseSetAccessedBy, device);
```

é€™æ¨£ CUDA driver å°±çŸ¥é“ï¼š

é€™å¡Šè¨˜æ†¶é«”ã€Œå¸¸é§ã€åœ¨å“ªå€‹ GPUï¼›

å“ªäº› GPU/CPU å…è¨±ç›´æ¥è¨ªå•ï¼›

æ¸›å°‘ä¸å¿…è¦çš„æ¬ç§»ã€‚

ğŸ§ª äº”ã€å¯¦éš›è§€å¯Ÿç­–ç•¥å»ºè­°

| ç›®çš„        | æ–¹æ³•                                              |
| --------- | ----------------------------------------------- |
| æƒ³çœ‹è³‡æ–™ç›®å‰åœ¨å“ªè£¡ | `cudaMemRangeGetAttribute()`                    |
| æƒ³çœ‹æ­·å²æ¬ç§»ç´€éŒ„  | Nsight Systems timeline                         |
| æƒ³é¿å…æ¬ç§»     | ä½¿ç”¨ `cudaMemPrefetchAsync()` + `cudaMemAdvise()` |
| æƒ³é–å®šåœ¨ GPU  | ä½¿ç”¨ `cudaMemAdviseSetPreferredLocation`          |

ğŸ¯ çµè«–ä¸€å¥è©±

æƒ³çŸ¥é“ Unified Memory è³‡æ–™ç›®å‰åœ¨å“ªå€‹è£ç½® â†’ ç”¨
cudaMemRangeGetAttribute(ptr, size, cudaMemRangeAttributeLastPrefetchLocation, â€¦)ã€‚

æƒ³ã€Œæ§åˆ¶ã€å®ƒåœ¨å“ªè£¡ â†’ ç”¨
cudaMemPrefetchAsync() + cudaMemAdvise()ã€‚