### å€‹ CUDA kernel functionï¼Œåˆç†çš„è¨­è¨ˆç‰½æ¶‰åˆ°å¤šå±¤è€ƒé‡ï¼Œå¾è³‡æ–™çš„å¤§å°èˆ‡å½¢ç‹€ã€GPU çš„æ¶æ§‹ç‰¹æ€§ã€è¨˜æ†¶é«”å­˜å–æ¨¡å¼ã€åˆ° batch è™•ç†ã€stream ç®¡ç†ç­‰ã€‚é€™è£¡çµ¦ä½ ä¸€ä»½çµæ§‹æ€§çš„æŒ‡å—ä¾†æ€è€ƒ CUDA kernel function çš„è¨­è¨ˆã€‚

ğŸ”§ æ ¸å¿ƒå•é¡Œï¼šä½ è¦åšä»€éº¼é¡å‹çš„ kernelï¼Ÿ
    ä¸åŒéœ€æ±‚æœƒæœ‰å®Œå…¨ä¸åŒçš„ kernel è¨­è¨ˆç­–ç•¥ï¼Œä¾‹å¦‚ï¼š

| é¡å‹                    | å…¸å‹ç¯„ä¾‹                         | è¨­è¨ˆè€ƒé‡                                |
| ----------------------- | -------------------------------- | --------------------------------------- |
| æ˜ å°„é¡ (map)            | normalizeã€resizeã€color convert | æ¯ pixel/thread ç¨ç«‹ï¼Œmemory coalescing |
| å·ç©é¡ (stencil)        | filterã€conv2d                   | shared memoryã€halo border è™•ç†         |
| èšåˆé¡ (reduce)         | sumã€argmaxã€histogram           | warp shuffle / block reduce             |
| é›¢æ•£é¡ (gather/scatter) | permutationã€masking             | åŸå­æ“ä½œã€memory access pattern         |

ğŸ§© åŸºæœ¬è¨­è¨ˆæ¡†æ¶ï¼ˆtemplateï¼‰

```cpp
__global__ void yourKernel(float* input, float* output, int width, int height, ...)
{
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    int idx = y * width + x;

    if (x < width && y < height) {
        // compute...
        output[idx] = input[idx] * 2.0f; // just example
    }
}
```

ğŸ§  è¨­è¨ˆæ€è·¯åˆ†å±¤è§£æ

1. ğŸš¦ Grid/block/thread è¨­å®š

    è‹¥è™•ç† 2D åœ–åƒï¼Œå»ºè­°ï¼š

    ```cpp
    dim3 block(32, 8); // æˆ– 16x16ï¼Œçœ‹ register / occupancy balance
    dim3 grid((width + block.x - 1) / block.x,(height + block.y - 1) / block.y);
    ```

    è‹¥ batch > 1ï¼Œå¯ç”¨ grid.z = batchï¼Œæˆ–ç”¨ batch loopã€‚

2. ğŸ—‚ï¸ è³‡æ–™å­˜å–èˆ‡æ’åˆ—
    å»ºè­°æ ¼å¼ï¼šbatch x channel x height x widthï¼ˆNCHWï¼‰
    è‹¥ç”¨ float* inputï¼Œæ³¨æ„ batch/channel offset è¨ˆç®—ã€‚
    ä½¿ç”¨ __ldg() å¯ hint cacheï¼ˆä½† Ampere ä¹‹å¾Œæ„ç¾©ä¸å¤§ï¼‰ã€‚

3. ğŸ§  è¨˜æ†¶é«”é¡å‹é¸æ“‡

    ä½¿ç”¨ shared memory æš«å­˜ tileï¼Œä»¥æ¸›å°‘ global memory I/Oã€‚
    ä½¿ç”¨ texture memoryï¼ˆæˆ– cudaTextureObject_tï¼‰æå‡è®€å–æ•ˆç‡èˆ‡æ’å€¼åŠŸèƒ½ã€‚

4. ğŸ§® batch è™•ç†

    å…©ç¨®æ–¹å¼ï¼š

    âœ… grid.z æ–¹å¼ï¼ˆé©åˆ batch size å°ï¼‰

        ```cpp
        int batch_id = blockIdx.z;
        float* batch_input = input + batch_id * img_size;
        float* batch_output = output + batch_id * img_size;
        ```

    âœ… stream + for-loop æ–¹å¼ï¼ˆå½ˆæ€§è¼ƒå¤§ï¼‰

        ```cpp
        for (int i = 0; i < batch; ++i)
        {
            yourKernel<<<...>>>(input + i*img_size, output + i*img_size, ...);
        }
        ```

âš™ï¸ å¯¦éš›è¨­è¨ˆç¯„ä¾‹ï¼šYOLOv8 Preprocess resize + normalize

    ```cpp
    __global__ void resize_normalize_kernel(
        uchar3* input, float* output,
        int in_w, int in_h, int out_w, int out_h, int batch_stride)
    {
        int x = blockIdx.x * blockDim.x + threadIdx.x;
        int y = blockIdx.y * blockDim.y + threadIdx.y;
        int b = blockIdx.z;

        if (x >= out_w || y >= out_h) return;

        float scale_x = static_cast<float>(in_w) / out_w;
        float scale_y = static_cast<float>(in_h) / out_h;

        int in_x = min(static_cast<int>(x * scale_x), in_w - 1);
        int in_y = min(static_cast<int>(y * scale_y), in_h - 1);

        uchar3 pixel = input[b * in_w * in_h + in_y * in_w + in_x];

        int out_idx = b * batch_stride + (y * out_w + x) * 3;
        output[out_idx + 0] = pixel.x / 255.0f;
        output[out_idx + 1] = pixel.y / 255.0f;
        output[out_idx + 2] = pixel.z / 255.0f;
    }
    ```

    å‘¼å«æ–¹å¼ï¼š

    ```cpp
    dim3 block(32, 8);
    dim3 grid((out_w + 31) / 32, (out_h + 7) / 8, batch);
    resize_normalize_kernel<<<grid, block>>>(...);
    ```

ğŸ§ª é™¤éŒ¯èˆ‡æœ€ä½³åŒ–å»ºè­°

| å·¥å…·/æŠ€å·§            | èªªæ˜                                              |
| -------------------- | ------------------------------------------------- |
| cuda-memcheck        | åµæ¸¬è¶Šç•Œå­˜å–ã€éæ³•ä½å€                            |
| Nsight Compute       | åˆ†æ kernel åŸ·è¡Œç“¶é ¸(memory-boundã€compute-bound) |
| occupancy calculator | åˆç†é¸ block sizeï¼Œé¿å… register overflow         |
| launch bounds        | æ˜ç¢ºæŒ‡å®š thread ä¸Šé™ä»¥æå‡æ€§èƒ½/é æ¸¬æ€§             |



cuda kernel èªæ³•

```cpp
myKernel<<<gridDim, blockDim, sharedMemBytes, stream>>>(...);
```

æ˜¯ CUDA ä¸­ã€Œkernel å‡½æ•¸å‘¼å«çš„å®Œæ•´å½¢å¼ã€ï¼Œç¸½å…±æœ‰å››å€‹åƒæ•¸ï¼Œæ¯”åŸºæœ¬çš„ <<<gridDim, blockDim>>> å¤šäº†å…©å€‹é€²éšåƒæ•¸ã€‚ä»¥ä¸‹æ˜¯æ¯å€‹åƒæ•¸çš„è©³ç´°èªªæ˜èˆ‡è¨­è¨ˆå»ºè­°ï¼š

ğŸ”§ å››å€‹åƒæ•¸èªªæ˜
1ï¸âƒ£ gridDimï¼ˆdim3 å‹åˆ¥ï¼‰
ç”¨é€”ï¼šæ±ºå®š GPU ä¸Šè¦åŸ·è¡Œå¤šå°‘å€‹ blockã€‚
é€šå¸¸è¨­è¨ˆç‚º 1Dã€2D æˆ– 3Dã€‚
æ¯å€‹ block å¯ä»¥è¢« GPU ç¨ç«‹èª¿åº¦ï¼Œä¸¦è¡ŒåŸ·è¡Œã€‚
ğŸ“Œ ç¯„ä¾‹ï¼š

```cpp
dim3 gridDim((width + blockDim.x - 1)/blockDim.x, (height + blockDim.y - 1)/blockDim.y);
```

2ï¸âƒ£ blockDimï¼ˆdim3 å‹åˆ¥ï¼‰
ç”¨é€”ï¼šæ±ºå®šæ¯å€‹ block ä¸­åŒ…å«å¤šå°‘å€‹ threadã€‚
æœ€å¤§ threads æ•¸é‡é™åˆ¶é€šå¸¸æ˜¯ 1024ï¼ˆä¾ GPU æ¶æ§‹å¯èƒ½ä¸åŒï¼‰
ğŸ“Œ å¸¸è¦‹é…ç½®ï¼š

```cpp
dim3 blockDim(32, 32);  // 1024 threads per block
```

â—é™åˆ¶æç¤ºï¼š

```cpp
blockDim.x * blockDim.y * blockDim.z â‰¤ 1024
```

éå¤§æœƒå°è‡´ launch failure

3ï¸âƒ£ sharedMemBytesï¼ˆsize_tï¼‰
ç”¨é€”ï¼šæŒ‡å®šæ¯å€‹ block æ‰€éœ€çš„ã€Œå‹•æ…‹ shared memory å¤§å°ã€ï¼ˆbyte ç‚ºå–®ä½ï¼‰ã€‚
èˆ‡ __shared__ å®£å‘Šçš„éœæ…‹ shared memory ä¸åŒï¼Œé€™å€‹åƒæ•¸æ˜¯å‹•æ…‹é…ç½®ç”¨çš„ã€‚
ğŸ§  åœ¨ kernel ä¸­é€™æ¨£å®£å‘Šï¼š

```cpp
extern __shared__ float sharedBuffer[];  // ä½¿ç”¨ sharedMemBytes é…ç½®
```

ğŸ“Œ ä½¿ç”¨ç¯„ä¾‹ï¼š

```cpp
size_t smem = sizeof(float) * 256;  // æ¯å€‹ block åˆ†é… 256 å€‹ float
myKernel<<<grid, block, smem>>>(...);
```

ğŸš¨ æ³¨æ„é™åˆ¶ï¼š
ä¸åŒ GPU æ¶æ§‹çš„ shared memory ä¸Šé™é€šå¸¸æ˜¯ 48KBã€96KBã€æˆ–æ›´é«˜ã€‚
è‹¥è¶…å‡º per-SM shared memory é™åˆ¶ï¼Œkernel æœƒ launch å¤±æ•—ã€‚

4ï¸âƒ£ streamï¼ˆcudaStream_tï¼‰
ç”¨é€”ï¼šæŒ‡å®šæ­¤ kernel åŸ·è¡Œåœ¨å“ªæ¢ CUDA stream ä¸Šã€‚
é è¨­å€¼ç‚º 0ï¼Œä»£è¡¨ä½¿ç”¨ default streamï¼ˆåºåˆ—åŸ·è¡Œï¼‰

ğŸ“Œ è‡ªè¨‚ stream çš„å¥½è™•ï¼š
æ”¯æ´éåŒæ­¥åŸ·è¡Œ
æ”¯æ´ pipelineï¼šå¦‚ copy + compute + copy
æ”¯æ´å¤š kernel é‡ç–ŠåŸ·è¡Œï¼ˆstream concurrencyï¼‰

ğŸ”§ å»ºç«‹èˆ‡ä½¿ç”¨ streamï¼š

```cpp
cudaStream_t stream;
cudaStreamCreate(&stream);
myKernel<<<grid, block, smem, stream>>>(...);
cudaStreamDestroy(stream);
```

ğŸš© å¯¦éš›æ‡‰ç”¨ä¾‹ï¼š
ä½ å¯èƒ½æœƒè®“ï¼š
Stream A è² è²¬å‰è™•ç†
Stream B è² è²¬æ¨è«–
Stream C è² è²¬å¾Œè™•ç†
é€™æ¨£å¯ä»¥æ¸›å°‘ GPU idle timeï¼Œæé«˜ throughputã€‚

ğŸ§ª ç¯„ä¾‹ï¼šç”¨å…±äº«è¨˜æ†¶é«”èˆ‡ stream åŠ é€Ÿå·ç©æ ¸

```cpp
__global__ void convKernel(const float* input, float* output) {
    extern __shared__ float tile[];
    int tx = threadIdx.x;
    int idx = blockIdx.x * blockDim.x + tx;

    // å°‡è³‡æ–™è®€å…¥ shared memory
    tile[tx] = input[idx];
    __syncthreads();

    // ... åšå·ç©è™•ç† ...
    output[idx] = tile[tx] * 2.0f;  // å‡è¨­åªæ˜¯ä¹˜å€‹ä¿‚æ•¸
}

void launchConv(const float* input, float* output, int size) {
    cudaStream_t stream;
    cudaStreamCreate(&stream);

    int threads = 256;
    int blocks = (size + threads - 1) / threads;
    size_t smem = threads * sizeof(float);  // æ¯å€‹ block ä½¿ç”¨ 1KB

    convKernel<<<blocks, threads, smem, stream>>>(input, output);
    cudaStreamDestroy(stream);
}
```

âš ï¸ æ³¨æ„äº‹é …èˆ‡æœ€ä½³å¯¦è¸

| åƒæ•¸           | é™åˆ¶ / æ³¨æ„                                  |
| -------------- | -------------------------------------------- |
| blockDim       | æ¯å€‹ block threads â‰¤ 1024(è¦– GPU è€Œå®š)       |
| sharedMemBytes | æ¯å€‹ block shared memory â‰¤ 48KB/96KB(ä¾ GPU) |
| stream         | å¯å¤šå€‹ stream åŒæ™‚åŸ·è¡Œï¼Œä½†æ³¨æ„è³‡æºç«¶çˆ­       |

ğŸ§  å•é¡Œæ€è€ƒï¼šä½•æ™‚è©²ç”¨ sharedMemBytesï¼Ÿ
è³‡æ–™æœ‰ç©ºé–“é‡ç”¨æ©Ÿæœƒï¼Œä¾‹å¦‚å·ç©ã€é„°è¿‘åƒç´ é‹ç®—ã€sorting
éœ€å¤§é‡ memory access è€Œ global memory access cost é«˜
æƒ³æ¸›å°‘ global memory çš„ bandwidth ä½¿ç”¨

