1. ä»€éº¼æ˜¯ Unified Memoryï¼ˆçµ±ä¸€è¨˜æ†¶é«”ï¼‰ï¼Ÿ

åœ¨ CUDA 6 ä¸­ï¼ŒNVIDIA å¼•å…¥äº† CUDA æ­·å²ä¸Šæœ€é‡è¦çš„ç¨‹å¼è¨­è¨ˆæ¨¡å‹æ”¹é€²ä¹‹ä¸€ â€”â€” Unified Memoryï¼ˆçµ±ä¸€è¨˜æ†¶é«”ï¼Œä»¥ä¸‹ç°¡ç¨± UMï¼‰ã€‚

åœ¨ä¸€èˆ¬çš„ PC ç³»çµ±ä¸­ï¼ŒCPU èˆ‡ GPU çš„è¨˜æ†¶é«”æ˜¯ç‰©ç†ä¸Šåˆ†é›¢çš„ï¼Œå…©è€…é€é PCIe åŒ¯æµæ’é€²è¡Œè³‡æ–™äº¤æ›ã€‚
åœ¨ CUDA 6.0 ä¹‹å‰ï¼Œç¨‹å¼è¨­è¨ˆå¸«å¿…é ˆéå¸¸æ¸…æ¥šé€™ä¸€é»ï¼Œä¸¦åœ¨ç¨‹å¼ç¢¼ä¸­æ‰‹å‹•è™•ç†è¨˜æ†¶é«”çš„åˆ†é…èˆ‡è³‡æ–™çš„å‚³è¼¸ï¼Œä¹Ÿå°±æ˜¯ï¼š

åœ¨ CPU èˆ‡ GPU å„è‡ªåˆ†é…è¨˜æ†¶é«”ç©ºé–“

ä½¿ç”¨ cudaMemcpy é€²è¡Œè³‡æ–™æ‹·è²ï¼ˆHost â†” Deviceï¼‰

ç¯„ä¾‹æ¯”è¼ƒ
å‚³çµ± CPU å¯«æ³•ï¼š

``` cpp
void sortfile(FILE *fp, int N)                    
{                                                   
    char *data = (char*) malloc(N);                               
    fread(data, 1, N, fp);                                 
    qsort(data, N, 1, compare);                          
    usedata(data);                                        
    free(data);                                           
}
```

ä½¿ç”¨ Unified Memory çš„ GPU å¯«æ³•ï¼š

``` cpp
void sortfile(FILE *fp, int N)
{
    char *data;
    cudaMallocManaged(&data, N);
  
    fread(data, 1, N, fp);
  
    qsort<<<...>>>(data, N, 1, compare);
    cudaDeviceSynchronize();  // ç­‰å¾… GPU åŸ·è¡Œå®Œæˆ
  
    usedata(data);
    cudaFree(data);
}
```


å¯ä»¥ç™¼ç¾å…©æ®µç¨‹å¼ç¢¼å¹¾ä¹ä¸€æ¨¡ä¸€æ¨£ã€‚
å”¯ä¸€çš„å·®åˆ¥æ˜¯ï¼š
1. ä½¿ç”¨ cudaMallocManaged() åˆ†é…è¨˜æ†¶é«”ï¼ˆå–ä»£ malloc()ï¼‰
2. GPU åŸ·è¡Œå®Œå¾Œéœ€è¦ cudaDeviceSynchronize() åŒæ­¥
3. ä¸å†éœ€è¦æ‰‹å‹•çš„ Host â†” Device æ‹·è²

åœ¨ CUDA 6.0 ä¹‹å‰ï¼Œå°æ‡‰çš„ç¨‹å¼æœƒé•·é€™æ¨£ï¼š

``` cpp
void sortfile(FILE *fp, int N)    
{
    char *h_data, *d_data;                                        
    h_data = (char*) malloc(N); 
    cudaMalloc(&d_data, N); 
 
    fread(h_data, 1, N, fp);   
    cudaMemcpy(d_data, h_data, N, cudaMemcpyHostToDevice);
 
    qsort<<<...>>>(d_data, N, 1, compare);
 
    cudaMemcpy(h_data, d_data, N, cudaMemcpyDeviceToHost);
     
    usedata(h_data);
    free(h_data); 
    cudaFree(d_data);
}
```

Unified Memory çš„å„ªé»
   1. ç°¡åŒ–è¨˜æ†¶é«”ç®¡ç†ï¼šä¸å†éœ€è¦åˆ†åˆ¥åˆ†é… host/device è¨˜æ†¶é«”ã€‚
   2. CPU/GPU å…±ç”¨åŒä¸€å€‹æŒ‡æ¨™ï¼šå¤§å¹…æ¸›å°‘ç¨‹å¼ç¢¼é‡èˆ‡éŒ¯èª¤é¢¨éšªã€‚
   3. èªè¨€æ•´åˆæ›´è‡ªç„¶ï¼šèˆ‡åŸç”Ÿ C/C++ èªæ³•æ›´ä¸€è‡´ã€‚
   4. æ›´æ–¹ä¾¿çš„ç¨‹å¼ç§»æ¤ï¼šæ¸›å°‘ä¸åŒå¹³å°é–“çš„ä¿®æ”¹æˆæœ¬ã€‚

2. Deep Copy çš„æƒ…å¢ƒ

å‰é¢çœ‹èµ·ä¾† UM å¥½åƒåªæ˜¯æ¸›å°‘äº†å¹¾è¡Œç¨‹å¼ç¢¼ï¼Œä½†ç•¶æˆ‘å€‘é¢å°æ›´è¤‡é›œçš„è³‡æ–™çµæ§‹æ™‚ï¼Œå®ƒçš„å¨åŠ›æ‰çœŸæ­£é¡¯ç¾ã€‚
å‡è¨­æˆ‘å€‘æœ‰ä»¥ä¸‹çµæ§‹é«”ï¼š

``` cpp
struct dataElem {
    int data1;
    int data2;
    char *text;
};
```

åœ¨æ²’æœ‰ UM çš„æƒ…æ³ä¸‹ï¼Œè¦å°‡å®ƒå‚³çµ¦ GPUï¼Œå°±å¾—é€™æ¨£å¯«ï¼š

```cpp
void launch(dataElem *elem) 
{
    dataElem *d_elem;
    char *d_text; 
 
    int textlen = strlen(elem->text); 
 
    cudaMalloc(&d_elem, sizeof(dataElem));
    cudaMalloc(&d_text, textlen);

    cudaMemcpy(d_elem, elem, sizeof(dataElem), cudaMemcpyHostToDevice);
    cudaMemcpy(d_text, elem->text, textlen, cudaMemcpyHostToDevice);

    // æ›´æ–° GPU ç«¯çš„ text æŒ‡æ¨™
    cudaMemcpy(&(d_elem->text), &d_text, sizeof(d_text), cudaMemcpyHostToDevice); 
 
    kernel<<<...>>>(d_elem);
}
```

é€™æ¨£éå¸¸ç¹ç‘£ã€‚
è€Œä½¿ç”¨ Unified Memory ä¹‹å¾Œï¼Œåªéœ€è¦ï¼š

``` cpp
void launch(dataElem *elem) 
{   
    kernel<<<...>>>(elem); 
}
```

æ˜¯ä¸æ˜¯æ¸…çˆ½å¤šäº†ï¼Ÿ

å°æ–¼åƒæ˜¯ éˆçµä¸²åˆ—ï¼ˆlinked listï¼‰ é€™ç¨®å¤šå±¤æŒ‡æ¨™çµæ§‹ï¼Œåœ¨æ²’æœ‰ UM çš„æƒ…æ³ä¸‹è¦åœ¨ GPU ä¸Šè™•ç†å¹¾ä¹æ˜¯æƒ¡å¤¢ï¼›ä½†æœ‰äº† UMï¼š
   1. å¯ä»¥åœ¨ CPU/GPU é–“ç›´æ¥å‚³éæ•´å€‹éˆçµä¸²åˆ—
   2. å¯ä»¥ä»»æ„ç«¯ä¿®æ”¹ç¯€é»å…§å®¹
   3. ä¸å¿…æ“”å¿ƒè¨˜æ†¶é«”åŒæ­¥èˆ‡å°æ‡‰å•é¡Œ
é›–ç„¶åœ¨ UM å‡ºç¾ä¹‹å‰ï¼Œä¹Ÿå¯ä»¥é€é Zero-Copy Memoryï¼ˆpinned host memoryï¼‰ ä¾†é”åˆ°é¡ä¼¼æ•ˆæœï¼Œä½† pinned memory çš„å­˜å–é€Ÿåº¦å—é™æ–¼ PCIe é »å¯¬ï¼Œæ•ˆèƒ½ä»ç„¶æœ‰é™ã€‚UM å‰‡èƒ½åœ¨è¨±å¤šæƒ…æ³ä¸‹å¸¶ä¾†æ›´å¥½çš„æ•ˆèƒ½ã€‚

3. åœ¨ C++ ä¸­ä½¿ç”¨ Unified Memory

ç¾ä»£ C++ é€šå¸¸ä¸ç›´æ¥ç”¨ malloc()ï¼Œè€Œæ˜¯é€é new é€²è¡Œå°è£ã€‚
æˆ‘å€‘å¯ä»¥è¦†å¯« operator new èˆ‡ operator delete ä¾†è®“é¡åˆ¥è‡ªå‹•ä½¿ç”¨ UMï¼š

``` cpp
class Managed {
public:
    void* operator new(size_t len) {
        void *ptr;
        cudaMallocManaged(&ptr, len);
        return ptr;
    }

    void operator delete(void *ptr) {
        cudaFree(ptr);
    }
};
```

ä»»ä½•ç¹¼æ‰¿ Managed çš„é¡åˆ¥ï¼Œéƒ½å¯ä»¥è‡ªå‹•ä½¿ç”¨ Unified Memoryã€‚
èˆ‰ä¾‹ä¾†èªªï¼Œä¸€å€‹è‡ªè¨‚çš„ String é¡åˆ¥ï¼š

``` cpp
class String : public Managed {
    int length;
    char *data;

public:
    // è¤‡è£½å»ºæ§‹å­å¯¦ç¾ pass-by-value
    String(const String &s) {
        length = s.length;
        cudaMallocManaged(&data, length);
        memcpy(data, s.data, length);
    }
};
```

é€™æ¨£å°±èƒ½è®“ç‰©ä»¶è‡ªå‹•åœ¨ Unified Memory ä¸Šé…ç½®ï¼Œä¸¦åœ¨ CPU/GPU é–“å…±ç”¨ã€‚

4. Unified Memory vs Unified Virtual Addressingï¼ˆUVAï¼‰

åˆ¥ææ··é€™å…©å€‹æ¦‚å¿µã€‚
UVAï¼ˆUnified Virtual Addressingï¼‰ æ—©åœ¨ CUDA 4.0 å°±å‡ºç¾äº†ï¼ŒUM æ˜¯å»ºç«‹åœ¨ UVA ä¹‹ä¸Šï¼Œä½†å®ƒå€‘ä¸¦ä¸æ˜¯åŒä¸€ä»¶äº‹ã€‚

UVA çš„ç›®æ¨™æ˜¯è®“ä»¥ä¸‹ä¸‰ç¨®è¨˜æ†¶é«”å…±ç”¨åŒä¸€è™›æ“¬ä½å€ç©ºé–“ï¼š

1. GPU device memory
2. Shared memoryï¼ˆon-chipï¼‰
3. Host memory

æ³¨æ„ï¼šthread-local çš„è¨˜æ†¶é«”ï¼ˆregisterã€local memoryï¼‰ä¸å±¬æ–¼ UVA ç¯„åœã€‚

UVA åªæ˜¯ã€Œçµ±ä¸€ä½å€ç©ºé–“ã€ï¼Œä½†ä¸æœƒè‡ªå‹•å¹«ä½ æ¬è³‡æ–™ã€‚
UM å‰‡æ˜¯é€²ä¸€æ­¥åœ¨ runtime æœŸé–“ç”± CUDA è‡ªå‹•é€²è¡Œé é¢é·ç§»ï¼ˆpage migrationï¼‰ï¼Œé”åˆ°çœŸæ­£çš„ã€Œè¨˜æ†¶é«”å…±äº«ã€æ•ˆæœã€‚

5. å¸¸è¦‹ç–‘å•

Q1ï¼šUnified Memory æœƒæ¶ˆé™¤ CPU èˆ‡ GPU ä¹‹é–“çš„æ‹·è²å—ï¼Ÿ
â†’ ä¸æœƒã€‚åªæ˜¯é€™éƒ¨åˆ†çš„æ‹·è²ç”± CUDA runtime è‡ªå‹•è™•ç†ï¼Œå°ç¨‹å¼è¨­è¨ˆå¸«é€æ˜è€Œå·²ã€‚
æ‹·è²çš„é–‹éŠ·ä»ç„¶å­˜åœ¨ï¼Œä¹Ÿä»éœ€æ³¨æ„ race condition èˆ‡è³‡æ–™ä¸€è‡´æ€§å•é¡Œã€‚
ç°¡å–®èªªï¼Œå¦‚æœä½ å·²ç¶“å¾ˆæœƒæ‰‹å‹•å„ªåŒ–è¨˜æ†¶é«”æ¬ç§»ï¼ŒUM ä¸æœƒæ›´å¿«ï¼Œä½†å®ƒæœƒè®“é–‹ç™¼æ›´è¼•é¬†ã€‚

Q2ï¼šæ—¢ç„¶é‚„æ˜¯æœƒæ‹·è²è³‡æ–™ï¼Œç‚ºä»€éº¼éœ€è¦ Compute Capability 3.0 ä»¥ä¸Šçš„ GPUï¼Ÿ
â†’ å› ç‚ºå¯¦éš›çš„ UM å¯¦ä½œä¾è³´æ–¼ç¡¬é«”çš„è™›æ“¬è¨˜æ†¶é«”èˆ‡é é·ç§»æ©Ÿåˆ¶ã€‚

å¾ Pascal æ¶æ§‹é–‹å§‹ï¼ŒGPU æä¾› 49-bit è™›æ“¬ä½å€ èˆ‡ æŒ‰éœ€é é·ç§»ï¼ˆon-demand page migrationï¼‰ï¼š

- GPU å¯ä»¥ç›´æ¥å°‹å€æ•´å€‹ç³»çµ±è¨˜æ†¶é«”èˆ‡å¤šå¼µ GPU çš„è¨˜æ†¶é«”ç©ºé–“
- æ”¯æ´è·¨ GPU çš„è¨˜æ†¶é«”å…±ç”¨èˆ‡ç³»çµ±å±¤ç´šåŸå­æ“ä½œ
- æ”¯æ´ã€Œout-of-coreã€é‹ç®—ï¼ˆè³‡æ–™é‡è¶…é GPU å¯¦é«”è¨˜æ†¶é«”ï¼‰

é€™äº›ç‰¹æ€§è®“ GPU å¯ä»¥åƒ CPU ä¸€æ¨£ï¼Œåœ¨éœ€è¦æ™‚æ‰è¼‰å…¥è³‡æ–™é ï¼ˆpage fault drivenï¼‰ï¼Œæ›´æœ‰æ•ˆç‡åœ°ä½¿ç”¨è¨˜æ†¶é«”è³‡æºã€‚

ç°¡å–®ç¸½çµï¼š

Unified Memory = è‡ªå‹•æ¬è³‡æ–™çš„ Unified Virtual Addressing + Page Migration + Runtime ç®¡ç†ã€‚
åœ¨é–‹ç™¼é«”é©—ä¸Šï¼ŒUM è®“ CUDA æ›´æ¥è¿‘ä¸€èˆ¬ C++ çš„ç¨‹å¼è¨­è¨ˆé‚è¼¯ï¼Œä¹Ÿè®“å¤š GPU æˆ–å¤§è¦æ¨¡è³‡æ–™è™•ç†è®Šå¾—æ›´ç°¡æ½”ã€‚

å‚³çµ± cudaMalloc + cudaMemcpy Unified Memory (cudaMallocManaged) ä½¿ç”¨æ™‚æ©Ÿåˆ¤æ–·

1. ç¸½è¦½ï¼šå…©è€…æ¯”è¼ƒè¡¨

| é …ç›®         | `cudaMalloc` + `cudaMemcpy`ï¼ˆå‚³çµ±ï¼‰ | `cudaMallocManaged`ï¼ˆUnified Memoryï¼‰      |
| ------------ | ----------------------------------- | ------------------------------------------ |
| è¨˜æ†¶é«”æ‰€åœ¨   | Host èˆ‡ Device å„è‡ªç¨ç«‹             | å…±ç”¨ä¸€å€‹çµ±ä¸€çš„è™›æ“¬ä½å€ç©ºé–“                 |
| æ¬ç§»æ§åˆ¶     | **æ‰‹å‹•** `cudaMemcpy()`             | **è‡ªå‹•**ï¼ˆç”± driver/page fault æ§åˆ¶ï¼‰      |
| æ•ˆèƒ½         | é€šå¸¸è¼ƒå¿«ï¼ˆå¯æœ€ä½³åŒ–è·¯å¾‘ï¼‰            | è¦– access pattern è€Œå®šï¼Œæœ‰ page fault é–‹éŠ· |
| èª¿è©¦å¯æ§æ€§   | æ˜ç¢ºã€å¯é æœŸ                        | éš±æ€§æ¬ç§»ï¼Œä¸å®¹æ˜“è¿½è¹¤æ•ˆèƒ½ç“¶é ¸               |
| é–‹ç™¼ä¾¿åˆ©æ€§   | ç¨ç¹ç‘£                              | è¶…æ–¹ä¾¿ï¼ˆä¸éœ€ memcpyï¼‰                      |
| æœ€ä½³æ‡‰ç”¨å ´æ™¯ | åš´æ ¼æ§åˆ¶è³‡æ–™æµçš„é«˜æ•ˆèƒ½æ‡‰ç”¨          | è·¨ CPU/GPU æ··åˆè¨ªå•çš„è¤‡é›œæ‡‰ç”¨              |
| æ”¯æ´æ€§       | å…¨ GPU æ¶æ§‹æ”¯æ´                     | éœ€è¦æ”¯æ´ Unified Memory çš„ GPUï¼ˆPascal+ï¼‰  |
| é å–æ§åˆ¶     | æ‰‹å‹• memcpy                         | å¯ç”¨ `cudaMemPrefetchAsync()` ä¸»å‹•æ¬ç§»     |
| page fault   | ç„¡                                  | æœ‰ï¼ˆlazy migrationï¼‰                       |
| å¤š GPU æ•ˆèƒ½  | éœ€è‡ªè¡Œåˆ†é…                          | Unified Memory å¯è·¨ GPUï¼ˆéœ€ prefetchï¼‰     |

2. ä½¿ç”¨æ™‚æ©Ÿåˆ¤æ–·
âœ… é¸æ“‡ Unified Memory (cudaMallocManaged)ï¼š
ğŸ‘‰ é©åˆã€Œæ–¹ä¾¿ > æ¥µè‡´æ•ˆèƒ½ã€çš„æƒ…å¢ƒ
   1. åŸå‹é–‹ç™¼ / Demo / å­¸ç¿’éšæ®µ
       - ä½ åªæ˜¯è¦é©—è­‰ kernel æ­£ä¸æ­£å¸¸ï¼Œä¸æƒ³æµªè²»æ™‚é–“åœ¨è³‡æ–™æ¬ç§»ä¸Šã€‚
       âœ… cudaMallocManaged ä¸€è¡Œæå®šã€‚
   2. CPU èˆ‡ GPU éƒ½éœ€è¦é »ç¹è¨ªå•åŒä¸€ä»½è³‡æ–™
       - ä¾‹å¦‚ï¼šéƒ¨åˆ†åœ¨ GPU é‹ç®—ï¼Œéƒ¨åˆ†åœ¨ CPU post-processingã€‚
       - Ex: GPU é‹ç®—å¾Œ CPU ç«‹åˆ»ç”¨çµæœç•«åœ– / åˆ†æã€‚
       âœ… Unified Memory è‡ªå‹•åŒæ­¥éå¸¸æ–¹ä¾¿ã€‚
   3. è³‡æ–™å¤§å°ä¸­ç­‰ï¼Œä¸æ˜¯è¶…ç´šå¤§
      - å¹¾å MB ~ å¹¾ç™¾ MB å…§é‚„è¡Œï¼Œpage migration overhead å¯æ¥å—ã€‚
   4. ä½¿ç”¨ Jetson / UMA æ¶æ§‹ï¼ˆå…±äº« DRAMï¼‰
      - Jetson Nanoã€Orinã€Xavierâ€¦ CPU/GPU æœ¬ä¾†å…±äº«å¯¦é«”è¨˜æ†¶é«”ã€‚
      âœ… Unified Memory å¹¾ä¹æ²’é¡å¤–é–‹éŠ·ï¼ˆå¯¦éš›å°±æ˜¯ shared RAMï¼‰ã€‚
   5. å¤š GPU æˆ–ç•°è³ªæ¶æ§‹ï¼ˆæ··åˆé‹ç®—ï¼‰
      - cudaMallocManaged + cudaMemPrefetchAsync()
       å¯ä»¥åœ¨ä¸åŒ GPU é–“é·ç§»è³‡æ–™ï¼Œdriver å¹«ä½ æå®šå¯è¦‹æ€§ã€‚
   6. æƒ³ç°¡åŒ–è¤‡é›œè³‡æ–™çµæ§‹ï¼ˆä¾‹å¦‚æŒ‡æ¨™å·¢ç‹€ structï¼‰
       - UM èƒ½è®“æ•´å€‹æ¨¹ç‹€è³‡æ–™ä¸€æ¬¡é…ç½®ï¼ˆå‚³çµ±éœ€è¦ä¸€å † malloc/copyï¼‰ã€‚
       âœ… å°å«å…§éƒ¨æŒ‡æ¨™çš„ç‰©ä»¶ç‰¹åˆ¥æ–¹ä¾¿ã€‚

âš¡ é¸æ“‡å‚³çµ± cudaMalloc + cudaMemcpyï¼š
ğŸ‘‰ é©åˆã€Œæ•ˆèƒ½èˆ‡å¯æ§æ€§ > æ–¹ä¾¿ã€çš„æƒ…å¢ƒ
   1. éœ€è¦åš´æ ¼æ§åˆ¶è³‡æ–™æµèˆ‡è¨˜æ†¶é«”ä½ˆå±€
      - ä½ çŸ¥é“ä»€éº¼æ™‚å€™è¦æ¬ã€æ¬å¤šå°‘ã€æ¬åˆ°å“ªè£¡ã€‚
      - Ex: DNN æ¨è«– pipelineã€å½±åƒå‰è™•ç† â†’ inference â†’ postprocessã€‚
      âœ… æ‰‹å‹•æ§åˆ¶æ•ˆèƒ½ç©©å®šï¼Œä¸æœƒè¢« UM çš„ page fault æ‰“äº‚ã€‚
   2. é•·æ™‚é–“é‹è¡Œã€å³æ™‚æ€§è¦æ±‚é«˜
      - Ex: è‡ªé§•è»Šå½±åƒæµã€å·¥æ¥­å³æ™‚æª¢æ¸¬ç³»çµ±ã€‚
      - page fault å»¶é²æœƒè®“ç³»çµ± jitterï¼ˆä¸ç©©ï¼‰ã€‚
   3. è¶…å¤§è³‡æ–™é›†ï¼ˆGB ç´šä»¥ä¸Šï¼‰
      - UM çš„ lazy migration æœƒå°è‡´åè¦† page migrationï¼Œæ•ˆç‡ä½ã€‚
      âœ… é å…ˆç”¨ pinned host memory + async copy æ›´æœ‰æ•ˆç‡ã€‚
   4. åªåœ¨ GPU ä¸Šæ“ä½œã€ä¸å› CPU
      - æ—¢ç„¶ CPU ä¸éœ€è¦è³‡æ–™ï¼ŒUM åªæ˜¯æµªè²»ã€‚
      âœ… ç›´æ¥ cudaMalloc ä¸€æ¬¡åˆ° GPUï¼Œcopy é€²å»è·‘åˆ°åº•ã€‚
   5. ä½ è¦åšåˆ° zero-copy pipeline / DMA æ•´åˆ
      - Ex: GStreamer + CUDAã€OpenCV + TensorRT çš„ pipelineã€‚
      âœ… å‚³çµ±åšæ³•æ‰èƒ½ç²¾ç¢ºæ§åˆ¶ pointer ç”Ÿå‘½é€±æœŸèˆ‡ device syncã€‚
   6. ä½ éœ€è¦è·¨ stream / è·¨ device çš„ fine-tune ç®¡ç†
      - cudaMemcpyAsync() + stream æ§åˆ¶èƒ½æ›´æ˜ç¢ºåœ° pipeline å¤š GPU é‹ç®—ã€‚
      âœ… UM é›£ä»¥ç²¾ç¢ºæ’ç¨‹ã€‚
3. Hybrid ç­–ç•¥ï¼ˆé€²éšç©å®¶ç”¨æ³•ï¼‰
    å…¶å¯¦ä¸æ˜¯éé»‘å³ç™½ï¼š
    è¨±å¤šé«˜æ•ˆèƒ½æ‡‰ç”¨æœƒã€Œæ··ç”¨ã€å…©è€…ï¼Œåƒé€™æ¨£ğŸ‘‡
    ç¯„ä¾‹ï¼šHybrid è¨­è¨ˆ

    ``` cpp
    // 1ï¸âƒ£ metadata ç”¨ Unified Memoryï¼ˆCPU/GPU å…±ç”¨ï¼‰
    cudaMallocManaged(&meta, sizeof(MetaStruct));

    // 2ï¸âƒ£ heavy data ç”¨ cudaMallocï¼ˆåªåœ¨ GPU ä¸Šï¼‰
    cudaMalloc(&gpuBuf, bufSize);
    cudaMemcpy(gpuBuf, hostBuf, bufSize, cudaMemcpyHostToDevice);
    ```
    é€™æ¨£ï¼š
    - meta çš„ç‹€æ…‹ CPU/GPU éƒ½èƒ½å³æ™‚çœ‹åˆ°ï¼›
    - ä½†å¤§é‡çš„å½±åƒ / tensor buffer ä¸æœƒè¢« UM çš„ page fault æ‹–æ…¢ã€‚
    - é€™æ˜¯ TensorRT / PyTorch ç­‰æ¡†æ¶åœ¨åº•å±¤å¸¸è¦‹çš„è¨­è¨ˆæ¨¡å¼ã€‚

        **é€™è£¡çš„ ã€Œmetadataã€ æŒ‡çš„å…¶å¯¦æ˜¯ï¼š**
        ğŸ§© æ§åˆ¶æ€§çš„å°è³‡æ–™ã€æè¿°è³‡æ–™ï¼ˆä¸æ˜¯ä¸»é«”è³‡æ–™æœ¬èº«ï¼‰
        ğŸš€ åœ¨ GPU ç¨‹å¼ä¸­çš„èªæ„ï¼š
        ç•¶ä½ çœ‹åˆ°åƒé€™æ¨£çš„ hybrid è¨­è¨ˆï¼š

        cudaMallocManaged(&meta, sizeof(MetaStruct));
        cudaMalloc(&gpuBuf, bufSize);


        é€™è£¡çš„ meta å°±æ˜¯ metadata â€”â€” å®ƒä¸æ˜¯å½±åƒæˆ– tensor çš„å…§å®¹ï¼Œè€Œæ˜¯ æè¿°æˆ–ç®¡ç†é€™äº›å…§å®¹çš„çµæ§‹åŒ–è³‡è¨Šã€‚
        ğŸ§  é€šå¸¸ metadata æœƒåŒ…å«çš„æ±è¥¿æœ‰ï¼š

    | é¡å‹       | ç¯„ä¾‹æ¬„ä½                        | åŠŸèƒ½                        |
    | ---------- | ------------------------------- | -------------------------- |
    | ğŸ“ å°ºå¯¸è³‡è¨Š | width, height, channels, stride | æè¿°å½±åƒæˆ– tensor çš„å½¢ç‹€    |
    | ğŸ”¢ ç´¢å¼•è³‡è¨Š | batch_idx, layer_id             | å¹«åŠ© GPU kernel æ‰¾å°è³‡æ–™   |
    | ğŸ§® ç‹€æ…‹æ§åˆ¶ | valid, ready, frame_count       | æ§åˆ¶ buffer æˆ– stream ç‹€æ…‹ |
    | ğŸ’¾ æŒ‡æ¨™æè¿° | `void* gpuBuf`, `size_t size`   | æŒ‡å‘å¯¦éš›çš„ GPU è³‡æ–™å€       |
    | ğŸ•’ æ™‚é–“æˆ³è¨˜ | timestamp, latency              | åšåŒæ­¥èˆ‡æ•ˆèƒ½åˆ†æç”¨          |


        é€™äº› metadata æœ¬èº«é«”ç©å¾ˆå°ï¼ˆé€šå¸¸ < 1KBï¼‰ï¼Œ
        ä½†å®ƒæœƒåœ¨ CPU èˆ‡ GPU é–“é »ç¹äº¤æ›è³‡è¨Šï¼ˆæ§åˆ¶æµï¼‰ï¼Œ
        å› æ­¤ç”¨ Unified Memory å¯ä»¥è®“é›™æ–¹ã€Œå³æ™‚å…±äº«ç‹€æ…‹ã€ï¼Œå…å»åè¦† cudaMemcpyã€‚

        âš™ï¸ ç‚ºä»€éº¼ä¸æŠŠ heavy data ä¹Ÿç”¨ Unified Memoryï¼Ÿ
        å› ç‚ºï¼š
        - å¤§å‹ tensor / å½±åƒï¼ˆå¹¾ MBï½GB ç´šï¼‰æœƒé€ æˆ page fault é–‹éŠ·å·¨å¤§
        - GPU åœ¨åŸ·è¡Œ kernel æ™‚è‹¥è¦è·¨ device pageï¼Œå°±æœƒé€ æˆ stall
            â†’ å°è‡´æ•ˆèƒ½å¤§å¹…ä¸‹é™ï¼ˆå¸¸è¦‹æ–¼ UM çš„ lazy migrationï¼‰

        æ‰€ä»¥å¯¦å‹™ä¸Šæ‰æœƒï¼š
        ğŸ”¸ ç”¨ Unified Memory å­˜æ”¾ metadataï¼ˆç‹€æ…‹å°ã€è¦é »ç¹äº’é€šï¼‰
        ğŸ”¸ ç”¨ cudaMalloc å­˜æ”¾ heavy dataï¼ˆå¤§è³‡æ–™å¡Šã€åªåœ¨ GPU ä¸Šç”¨ï¼‰

        ğŸ“¦ å¯¦ä¾‹ï¼šTensorRT / PyTorch éƒ½æ˜¯é€™æ¨£æ

        ä»¥ TensorRT çš„ä¾‹å­ä¾†èªªï¼š
        - IExecutionContextã€Bindingsã€Dims â†’ å±¬æ–¼ metadataï¼ˆCPU/GPU å…±ç”¨ï¼‰
        - Device Buffer â†’ å±¬æ–¼ heavy dataï¼ˆåªåœ¨ GPU ä¸Šï¼‰
        åŒæ¨£åœ°ï¼ŒPyTorch tensor çš„ .data_ptr() æŒ‡å‘ GPU bufferï¼Œ
        ä½†å®ƒçš„ TensorImplï¼ˆshape / dtype / requires_grad ç­‰ï¼‰å°±æ˜¯ metadataã€‚

1. æ•ˆèƒ½å¯¦æ¸¬å·®ç•°

    | æ¨¡å¼                            | 100 MB è³‡æ–™å‚³è¼¸æ™‚é–“ï¼ˆPCIe 4.0ï¼‰ | å‚™è¨»                   |
    | ------------------------------- | ------------------------------- | ---------------------- |
    | `cudaMemcpy` (Pinned Host)      | ç´„ 5â€“7 ms                       | ç©©å®šå¯é æ¸¬             |
    | Unified Memory + Lazy Migration | ç´„ 8â€“15 ms                      | é¦–æ¬¡è¨ªå•å»¶é²é«˜ï¼Œå¾ŒçºŒå¿« |
    | Unified Memory + Prefetch       | ç´„ 6â€“8 ms                       | æ¥è¿‘ memcpy æ•ˆèƒ½       |
    ğŸ’¡ å°æŠ€å·§ï¼šåœ¨ UM æ¨¡å¼ä¸‹åŠ ä¸Š
    cudaMemPrefetchAsync(ptr, size, device_id) å¹¾ä¹å¯æ¥è¿‘ memcpy æ•ˆèƒ½ã€‚

2. å¯¦æˆ°å»ºè­°
   
    | éœ€æ±‚                        | å»ºè­°                                 |
    | --------------------------- | ------------------------------------ |
    | Prototype / å­¸ç¿’            | âœ… `cudaMallocManaged`                |
    | åµŒå…¥å¼ï¼ˆJetson / UMAï¼‰      | âœ… `cudaMallocManaged`                |
    | é«˜æ•ˆèƒ½æ¨è«–ç³»çµ±              | âš¡ å‚³çµ± + pinned memory               |
    | å¤§å‹å½±åƒ/å½±ç‰‡æµ pipeline    | âš¡ å‚³çµ± + async copy                  |
    | CPU/GPU æ··åˆè¨ˆç®—            | âœ… `cudaMallocManaged`ï¼ˆå¯ prefetchï¼‰ |
    | Realtime / low-latency ä»»å‹™ | âŒ é¿å… UMï¼Œæ”¹ç”¨é¡¯å¼æ¬ç§»              |

3. åˆ¤æ–·é‚è¼¯

    ``` bash
    æ˜¯å¦ CPU ä¹Ÿè¦è®€å– GPU çµæœï¼Ÿ
    â”œâ”€â”€ å¦ â†’ cudaMalloc + cudaMemcpy
    â””â”€â”€ æ˜¯ â†’
        æ˜¯å¦è³‡æ–™é‡å°/ä¸­ç­‰ï¼Ÿ
            â”œâ”€â”€ æ˜¯ â†’ cudaMallocManaged
            â””â”€â”€ å¦ â†’
                æ˜¯å¦ Jetson / UMAï¼Ÿ
                    â”œâ”€â”€ æ˜¯ â†’ cudaMallocManaged
                    â””â”€â”€ å¦ â†’ cudaMalloc + cudaMemcpyAsync + pinned host
    ```

4. åŠ ç¢¼ï¼šå…©è€…çµåˆ prefetch
    é€™æ¨£å°±ç­‰æ–¼æ‰‹å‹•æ§åˆ¶ UM çš„æ¬ç§»æ™‚æ©Ÿï¼Œ
    æ•ˆèƒ½æ¥è¿‘å‚³çµ± memcpyï¼Œä½†ç¶­æŒ Unified Memory çš„ä¾¿åˆ©æ€§ã€‚

    ç¸½çµä¸€å¥è©±ï¼š

    ğŸ”¹ å¦‚æœä½ åœ¨åšã€Œå¿«é€Ÿå¯¦é©—ã€åµŒå…¥å¼ã€CPU-GPU å…±ç”¨è³‡æ–™ã€ï¼Œè«‹ç”¨ cudaMallocManaged()ã€‚
    ğŸ”¹ å¦‚æœä½ åœ¨åšã€Œæ•ˆèƒ½é—œéµã€å³æ™‚ç³»çµ±ã€GPU-only pipelineã€ï¼Œè«‹ç”¨ cudaMalloc + cudaMemcpy()ã€‚
    ğŸ”¹ æƒ³å…©è€…å…¼é¡§ï¼Œè«‹ç”¨ UM + prefetchã€‚