### cuda dim3

dim3 æ˜¯ CUDA è£¡é¢ç”¨ä¾†å®šç¾© gridï¼ˆç¶²æ ¼ï¼‰èˆ‡ blockï¼ˆå€å¡Šï¼‰ç¶­åº¦çš„çµæ§‹ï¼ŒåŸºæœ¬ä¸Šå°±æ˜¯ä¸€å€‹æœ€å¤šå¯æ”¯æ´ä¸‰ç¶­ï¼ˆx, y, zï¼‰çš„æ•´æ•¸å‘é‡ï¼Œç”¨ä¾†å‘Šè¨´ GPU kernel å•Ÿå‹•æ™‚è¦é–‹å¤šå°‘ threadã€‚

ğŸš€ å®šç¾©

``` cpp
struct dim3 {
    unsigned int x, y, z;
    __host__ __device__
    dim3(unsigned int vx = 1, unsigned int vy = 1, unsigned int vz = 1)
        : x(vx), y(vy), z(vz) {}
};
```

ä¹Ÿå°±æ˜¯èªªï¼Œä½ å¯ä»¥åƒé€™æ¨£ç”¨ï¼š

``` cpp
dim3 block(32, 8, 1);
dim3 grid(16, 16, 1);
myKernel<<<grid, block>>>(...);
```

ğŸ§  æ ¸å¿ƒæ¦‚å¿µ
ç•¶ä½ å‘¼å« kernel æ™‚ï¼š

``` cpp
kernel<<<grid, block>>>(args...);
```

å…¶å¯¦æœƒç”¢ç”Ÿï¼š
- grid.x * grid.y * grid.z å€‹ block
- æ¯å€‹ block è£¡é¢æœ‰ block.x * block.y * block.z å€‹ thread
æ•´é«” threads æ•¸é‡ = gridDim * blockDim

ğŸ“¦ ç¯„ä¾‹ï¼š2D å½±åƒæ“ä½œ
å‡è¨­ä½ è¦è™•ç†ä¸€å¼µå½±åƒï¼ˆå¯¬ 640ã€é«˜ 480ï¼‰ï¼Œä½ å¯ä»¥é€™æ¨£é…ç½®ï¼š

``` cpp
int width = 640;
int height = 480;

dim3 block(32, 16);
dim3 grid((width + block.x - 1) / block.x,
          (height + block.y - 1) / block.y);

processImage<<<grid, block>>>(...);
```

é€™æ¨£ï¼š

- æ¯å€‹ block æœ‰ 32 Ã— 16 = 512 threads
- grid å¤§å°ç´„ç‚º (20, 30) â†’ å…± 600 blocks
ç¸½ threads ç´„ 600 Ã— 512 = 307,200ï¼Œå‰›å¥½èƒ½ cover æ•´å¼µå½±åƒã€‚

ğŸ§© åœ¨ kernel è£¡çš„åº§æ¨™è¨ˆç®—

``` cpp
__global__ void processImage(uint8_t* img, int width, int height) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;

    if (x >= width || y >= height) return;

    int idx = y * width + x;
    img[idx] = 255 - img[idx]; // åç›¸è™•ç†
}
```

âš™ï¸ ç¶­åº¦ä½¿ç”¨å»ºè­°

| ç”¨é€”           | ç¶­åº¦ | èªªæ˜                                         |
| ------------ | -- | ------------------------------------------ |
| å‘é‡ã€åˆ—è¡¨        | 1D | `dim3 block(256); dim3 grid((N+255)/256);` |
| å½±åƒ (HÃ—W)     | 2D | `dim3 block(16, 16);`                      |
| é«”ç©è³‡æ–™ (HÃ—WÃ—D) | 3D | `dim3 block(8, 8, 8);`                     |


ğŸš§ å°æé†’ï¼šé›–ç„¶ dim3 æ”¯æ´ z ç¶­åº¦ï¼Œä½†å¤§å¤šæ•¸ GPU çš„ blockDim.z é€šå¸¸ä¸è¶…é 64ï¼ˆå¯¦éš›ä¾ GPU compute capability è€Œå®šï¼‰ã€‚

**CUDA çš„ dim3 ä¾†ä¸€æ¬¡è™•ç†å¤šå¼µåœ–ã€‚**

ğŸ§© ç›®æ¨™æƒ…å¢ƒ

å‡è¨­ï¼š
- ä½ æœ‰ N å¼µåœ–ç‰‡
- æ¯å¼µåœ–ç‰‡å¤§å°ç‚º W Ã— H
- ä½ å¸Œæœ› kernel èƒ½åŒæ™‚è™•ç†å¤šå¼µï¼ˆä¾‹å¦‚ batch warpAffineã€batch normalizeã€batch inference å‰è™•ç†ï¼‰

ğŸš€ å…¸å‹ dim3 é…ç½®
æˆ‘å€‘å¯ä»¥ç”¨ 3D grid/block ä¾† mappingï¼š

``` cpp
dim3 block(16, 16, 1);
dim3 grid(
    (W + block.x - 1) / block.x,   // X å°æ‡‰ width
    (H + block.y - 1) / block.y,   // Y å°æ‡‰ height
    N                              // Z å°æ‡‰ batch
);
```

ç„¶å¾Œåœ¨ kernel è£¡é¢å–å‡ºåº§æ¨™ï¼š

``` cpp
__global__ void processBatch(
    uint8_t* src, float* dst,
    int W, int H, int N, int srcPitch, int dstPitch)
{
    int x = blockIdx.x * blockDim.x + threadIdx.x; // width
    int y = blockIdx.y * blockDim.y + threadIdx.y; // height
    int n = blockIdx.z;                            // batch idx (image id)

    if (x >= W || y >= H || n >= N) return;

    // æ¯å¼µåœ–åœ¨è¨˜æ†¶é«”ä¸­çš„èµ·å§‹ä½ç§»
    int srcOffset = n * srcPitch * H;
    int dstOffset = n * dstPitch * H;

    int idx = y * srcPitch + x;
    dst[dstOffset + idx] = 255 - src[srcOffset + idx];
}
```

ğŸ§  é‡é»èªªæ˜

| ç¶­åº¦        | å°æ‡‰          | èªªæ˜                      |
| --------- | ----------- | ----------------------- |
| `block.x` | æ¯å¼µåœ–çš„å¯¬åº¦åˆ†å·¥    | ä¸€å€‹ block è² è²¬ä¸€å°å¡Š 16Ã—16 å€åŸŸ |
| `block.y` | æ¯å¼µåœ–çš„é«˜åº¦åˆ†å·¥    | åŒä¸Š                      |
| `block.z` | ä¸ä½¿ç”¨ï¼ˆé€šå¸¸ = 1ï¼‰ | å› ç‚ºä¸€å¼µåœ–é€šå¸¸æ˜¯ 2D è™•ç†          |
| `grid.x`  | åœ–ç‰‡å¯¬åº¦åˆ† block | `(W+bx-1)/bx`           |
| `grid.y`  | åœ–ç‰‡é«˜åº¦åˆ† block | `(H+by-1)/by`           |
| `grid.z`  | batch index | `N`                     |

âš¡ Example
å‡è¨­ï¼š

``` cpp
N = 8;
W = 640;
H = 480;

dim3 block(32, 16);
dim3 grid((W + block.x - 1) / block.x,
          (H + block.y - 1) / block.y,
          N);
```

â†’
é€™æœƒç”¢ç”Ÿï¼š
- grid.z = 8 â†’ ä¸€æ¬¡è™•ç† 8 å¼µåœ–
- æ¯å¼µåœ–è¢«åˆ‡æˆ 20 Ã— 30 å€‹ block
- æ¯å€‹ block 512 threads
â†’ GPU åŒæ™‚è·‘ 8 * 20 * 30 * 512 = 2,457,600 threadsï¼ˆæœƒè‡ªå‹•ç”± SM æ’ç¨‹ï¼‰

âš™ï¸ é€²éšç‰ˆï¼šä½¿ç”¨ shared memory per image
è‹¥æ¯å¼µåœ–éœ€è¦å„è‡ªçš„è®Šæ›çŸ©é™£ï¼ˆä¾‹å¦‚ batch warpAffineï¼‰ï¼Œå¯é€™æ¨£è¨­è¨ˆï¼š

``` cpp
__global__ void batchWarpAffine(
    const uchar3* src, float* dst,
    const float* warpMatrices, // N Ã— 6
    int W, int H, int N)
{
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    int n = blockIdx.z;

    if (x >= W || y >= H || n >= N) return;

    __shared__ float M[6];
    if (threadIdx.x == 0 && threadIdx.y == 0) {
        const float* srcM = warpMatrices + n * 6;
        for (int i = 0; i < 6; ++i) M[i] = srcM[i];
    }
    __syncthreads();

    // warp
    float srcX = M[0]*x + M[1]*y + M[2];
    float srcY = M[3]*x + M[4]*y + M[5];

    // ... sample & write dst[n][y][x]
}
```

